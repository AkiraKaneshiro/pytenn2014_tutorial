{
 "metadata": {
  "name": "",
  "signature": "sha256:62d6c0bca035bbf7cbe3e1ab4ffb9c88a040dbcf3cd51690011941a482c6a0af"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Wrangling with Pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python is a terrific platform for statistical data analysis partly because of the features of the language itself, but also because of a rich suite of 3rd party packages that provide robust and flexible data structures, efficient implementations of mathematical and statistical functions, and facitities for generating publication-quality graphics. Pandas is at the top of the \"scientific stack\", because it allows data to be imported, manipulated and exported so easily. In contrast, NumPy supports the bottom of the stack with fundamental infrastructure for array operations, mathematical calculations, and random number generation. \n",
      "\n",
      "We will cover both of these in some detail before getting down to the business of analyzing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Set some Pandas options\n",
      "pd.set_option('html', False)\n",
      "pd.set_option('max_columns', 30)\n",
      "pd.set_option('max_rows', 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "NumPy\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most fundamental third-party package for scientific computing in Python is NumPy, which provides multidimensional array data types, along with associated functions and methods to manipulate them. While Python comes with several container types (`list`,`tuple`,`dict`), NumPy's arrays are implemented closer to the hardware, and are therefore more efficient than the built-in types. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Basics of Numpy arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main object provided by numpy is a powerful array.  We'll start by exploring how the numpy array differs from Python lists.  We start by creating a simple list and an array with the same contents of the list:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_list = range(1000)\n",
      "an_array = np.arange(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is what the array looks like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "an_array[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(an_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeit [i**2 for i in a_list]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeit an_array**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Elements of a one-dimensional array are indexed with square brackets, as with lists:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "an_array[5:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first difference to note between lists and arrays is that arrays are *homogeneous*; i.e. all elements of an array must be of the same type.  In contrast, lists can contain elements of arbitrary type. For example, we can change the last element in our list above to be a string:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_list[0] = 'a string inside a list'\n",
      "a_list[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "an_array[0] = 'a string inside an array'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The information about the type of an array is contained in its *dtype* attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "an_array.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once an array has been created, its dtype is fixed and it can only store elements of the same type.  For this example where the dtype is integer, if we store a floating point number it will be automatically converted into an integer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "an_array[0] = 1.234\n",
      "an_array[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `linspace` and `logspace` functions to create linearly and logarithmically-spaced grids respectively, with a fixed number of points and including both ends of the specified interval:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.linspace(0, 1, num=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.logspace(1, 4, num=4)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is often useful to create arrays with random numbers that follow a specific distribution.  The `np.random` module contains a number of functions that can be used to this effect, for example this will produce an array of 5 random samples taken from a standard normal distribution (0 mean and variance 1):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.randn(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "whereas the following will also give 5 samples, but from a normal distribution with a mean of 10 and a variance of 3:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_10 = np.random.normal(loc=10, scale=3, size=10)\n",
      "norm_10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Indexing with other arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above we saw how to index arrays with single numbers and slices, just like Python lists.  But arrays allow for a more sophisticated kind of indexing which is very powerful: you can index an array with another array, and in particular with an array of boolean values.  This is particluarly useful to extract information from an array that matches a certain condition.\n",
      "\n",
      "Consider for example that in the array `norm10` we want to replace all values above 9 with the value 0.  We can do so by first finding the *mask* that indicates where this condition is `True` or `False`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask = norm_10 > 9\n",
      "mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have this mask, we can use it to either read those values or to reset them to 0:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_10[mask]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_10[mask] = 0\n",
      "print norm_10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_10[np.nonzero(norm_10)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Multidimensional Arrays\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numpy can create arrays of aribtrary dimensions, and all the methods illustrated in the previous section work with more than one dimension. For example, a list of lists can be used to initialize a two dimensional array:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array_2d = np.array([[1, 2], [3, 4]])\n",
      "array_2d.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With two-dimensional arrays we start seeing the power of numpy: while a nested list can be indexed using repeatedly the `[ ]` operator, multidimensional arrays support a much more natural indexing syntax with a single `[ ]` and a set of indices separated by commas:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array_2d[0,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The shape of an array can be changed at any time, as long as the total number of elements is unchanged.  For example, if we want a 2x4 array with numbers increasing from 0, the easiest way to create it is via the numpy array's `reshape` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array = np.arange(8).reshape(2,4)\n",
      "print md_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With multidimensional arrays, you can also use slices, and you can mix and match slices and single indices in the different dimensions (using the same array as above):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array[1, 2:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array[:, 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you only provide one index, then you will get the corresponding row."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays have a slew of useful attributes and methods:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.ndim"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.nbytes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.min(), md_array.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.sum(), md_array.prod()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.mean(), md_array.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays may be summarized along specified axes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, more generally:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_array = np.random.random((3,2,3,4))\n",
      "random_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_array.sum(2).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NumPy arrays support all standard arithmetic operations, which are typically applied element-wise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_array = np.random.randn(4)\n",
      "second_array = np.random.randn(4)\n",
      "\n",
      "first_array, second_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_array * second_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When operating on scalars (zero-dimensional objects), *broadcasting* is used to apply the operation to each element: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_array * 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Broadcasting also works for multidimensional arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array * first_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the above, NumPy compares the trailing dimensions of each array, and adds dimsnsions of length 1 for the remaining dimensions, before multiplying. Hence, the following will not work:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array * np.array([-1, 2.3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be made to work either by \"injecting\" an additional axis, or by transposing the first array:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array * np.array([-1, 2.3])[:, np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.T * np.array([-1, 2.3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some may have predicted the multiply operator to perform matrix multiplication on two array arguments, rather than element-wise multiplication. NumPy includes a linear algebra library, and matrix mutliplication can be carried out using the `dot` (*i.e.* dot product) function or method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_array.dot(first_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.dot(md_array, first_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction to Pandas\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**pandas** is a Python package providing fast, flexible, and expressive data structures designed to work with *relational* or *labeled* data both. It is a fundamental high-level building block for doing practical, real world data analysis in Python. \n",
      "\n",
      "pandas is well suited for:\n",
      "\n",
      "- Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
      "- Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
      "- Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
      "- Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
      "\n",
      "\n",
      "Key features:\n",
      "    \n",
      "- Easy handling of **missing data**\n",
      "- **Size mutability**: columns can be inserted and deleted from DataFrame and higher dimensional objects\n",
      "- Automatic and explicit **data alignment**: objects can be explicitly aligned to a set of labels, or the data can be aligned automatically\n",
      "- Powerful, flexible **group by functionality** to perform split-apply-combine operations on data sets\n",
      "- Intelligent label-based **slicing, fancy indexing, and subsetting** of large data sets\n",
      "- Intuitive **merging and joining** data sets\n",
      "- Flexible **reshaping and pivoting** of data sets\n",
      "- **Hierarchical labeling** of axes\n",
      "- Robust **IO tools** for loading data from flat files, Excel files, databases, and HDF5\n",
      "- **Time series functionality**: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "HTML(\"<iframe src=http://pandas.pydata.org width=800 height=350></iframe>\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pandas Data Structures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Series\n",
      "\n",
      "A **Series** is a single vector of data (like a NumPy array) with an *index* that labels each element in the vector."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = pd.Series([632, 1638, 569, 115])\n",
      "counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If an index is not specified, a default sequence of integers is assigned as the index. A NumPy array comprises the values of the `Series`, while the index is a pandas `Index` object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can assign meaningful labels to the index, if they are available:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria = pd.Series([632, 1638, 569, 115], \n",
      "    index=['Firmicutes', 'Proteobacteria', 'Actinobacteria', 'Bacteroidetes'])\n",
      "\n",
      "bacteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These labels can be used to refer to the values in the `Series`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria['Actinobacteria']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria[[name.endswith('bacteria') for name in bacteria.index]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[name.endswith('bacteria') for name in bacteria.index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the indexing operation preserved the association between the values and the corresponding indices.\n",
      "\n",
      "We can still use positional indexing if we wish."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can give both the array of values and the index meaningful labels themselves:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria.name = 'counts'\n",
      "bacteria.index.name = 'phylum'\n",
      "bacteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NumPy's math functions and other operations can be applied to Series without losing the data structure."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.log(bacteria)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also filter according to the values in the `Series`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria[bacteria>1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A `Series` can be thought of as an ordered key-value store. In fact, we can create one from a `dict`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria_dict = {'Firmicutes': 632, 'Proteobacteria': 1638, 'Actinobacteria': 569, 'Bacteroidetes': 115}\n",
      "pd.Series(bacteria_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the `Series` is created in key-sorted order.\n",
      "\n",
      "If we pass a custom index to `Series`, it will select the corresponding values from the dict, and treat indices without corrsponding values as missing. Pandas uses the `NaN` (not a number) type for missing values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2 = pd.Series(bacteria_dict, index=['Cyanobacteria','Firmicutes','Proteobacteria','Actinobacteria'])\n",
      "bacteria2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2.isnull()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Critically, the labels are used to **align data** when used in operations with other Series objects:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria + bacteria2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Contrast this with NumPy arrays, where arrays of the same length will combine values element-wise; adding Series combined values with the same label in the resulting series. Notice also that the missing values were propogated by addition."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### DataFrame\n",
      "\n",
      "Inevitably, we want to be able to store, view and manipulate data that is *multivariate*, where for every index there are multiple fields or columns of data, often of varying data type.\n",
      "\n",
      "A `DataFrame` is a tabular data structure, encapsulating multiple series like columns in a spreadsheet. Data are stored internally as a 2-dimensional object, but the `DataFrame` allows us to represent and manipulate higher-dimensional data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame({'value':[632, 1638, 569, 115, 433, 1130, 754, 555],\n",
      "                     'patient':[1, 1, 1, 1, 2, 2, 2, 2],\n",
      "                     'phylum':['Firmicutes', 'Proteobacteria', 'Actinobacteria', \n",
      "    'Bacteroidetes', 'Firmicutes', 'Proteobacteria', 'Actinobacteria', 'Bacteroidetes']})\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice the `DataFrame` is sorted by column name. We can change the order by indexing them in the order we desire:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[['phylum','value','patient']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A `DataFrame` has a second index, representing the columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wish to access columns, we can do so either by dict-like indexing or by attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['value']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data.value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data[['value']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice this is different than with `Series`, where dict-like indexing retrieved a particular element (row). If we want access to a row in a `DataFrame`, we index its `ix` attribute.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.ix[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its important to note that the Series returned when a DataFrame is indexted is merely a **view** on the DataFrame, and not a copy of the data itself. So you must be cautious when manipulating this data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vals = data.value\n",
      "vals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vals[5] = 0\n",
      "vals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vals = data.value.copy()\n",
      "vals[5] = 1000\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can create or modify columns by assignment:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.value[3] = 14\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['year'] = 2013\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But note, we cannot use the attribute indexing method to add a new column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.treatment = 1\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.treatment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specifying a `Series` as a new columns cause its values to be added according to the `DataFrame`'s index:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treatment = pd.Series([0]*4 + [1]*2)\n",
      "treatment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['treatment'] = treatment\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other Python data structures (ones without an index) need to be the same length as the `DataFrame`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "month = ['Jan', 'Feb', 'Mar', 'Apr']\n",
      "data['month'] = month"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can extract the underlying data as a simple `ndarray` by accessing the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that because of the mix of string and integer (and `NaN`) values, the dtype of the array is `object`. The dtype will automatically be chosen to be as general as needed to accomodate all the columns."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas uses a custom data structure to represent the indices of Series and DataFrames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Index objects are immutable:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.index[0] = 15"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is so that Index objects can be shared between data structures without fear that they will be changed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2.index = bacteria.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Importing data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A key, but often under-appreciated, step in data analysis is importing the data that we wish to analyze. Though it is easy to load basic data structures into Python using built-in tools or those provided by packages like NumPy, it is non-trivial to import structured data well, and to easily convert this input into a robust data structure:\n",
      "\n",
      "    genes = np.loadtxt(\"genes.csv\", delimiter=\",\", dtype=[('gene', '|S10'), ('value', '<f4')])\n",
      "\n",
      "Pandas provides a convenient set of functions for importing tabular data in a number of formats directly into a `DataFrame` object. These functions include a slew of options to perform type inference, indexing, parsing, iterating and cleaning automatically as data are imported."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with some more bacteria data, stored in csv format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat data/microbiome.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This table can be read into a DataFrame using `read_csv`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb = pd.read_csv(\"data/microbiome.csv\")\n",
      "mb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that `read_csv` automatically considered the first row in the file to be a header row.\n",
      "\n",
      "We can override default behavior by customizing some the arguments, like `header`, `names` or `index_col`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"data/microbiome.csv\", header=None).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`read_csv` is just a convenience function for `read_table`, since csv is such a common format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb = pd.read_table(\"data/microbiome.csv\", sep=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `sep` argument can be customized as needed to accomodate arbitrary separators. For example, we can use a regular expression to define a variable amount of whitespace, which is unfortunately very common in some data formats: \n",
      "    \n",
      "    sep='\\s+'"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a more useful index, we can specify the first two columns, which together provide a unique index to the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb = pd.read_csv(\"data/microbiome.csv\", index_col=['Taxon','Patient'])\n",
      "mb.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is called a *hierarchical* index, which we will revisit later in the tutorial."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we have sections of data that we do not wish to import (for example, known bad data), we can populate the `skiprows` argument:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"data/microbiome.csv\", skiprows=[3,4,6]).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conversely, if we only want to import a small number of rows from, say, a very large data file we can use `nrows`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"data/microbiome.csv\", nrows=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternately, if we want to process our data in reasonable chunks, the `chunksize` argument will return an iterable object that can be employed in a data processing loop. For example, our microbiome data are organized by bacterial phylum, with 15 patients represented in each:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_chunks = pd.read_csv(\"data/microbiome.csv\", chunksize=15)\n",
      "\n",
      "mean_tissue = {chunk.Taxon[0]:chunk.Tissue.mean() for chunk in data_chunks}\n",
      "    \n",
      "mean_tissue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most real-world data is incomplete, with values missing due to incomplete observation, data entry or transcription error, or other reasons. Pandas will automatically recognize and parse common missing data indicators, including `NA` and `NULL`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat data/microbiome_missing.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"data/microbiome_missing.csv\").head(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above, Pandas recognized `NA` and an empty field as missing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.isnull(pd.read_csv(\"data/microbiome_missing.csv\")).head(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, there will sometimes be inconsistency with the conventions for missing data. In this example, there is a question mark \"?\" and a large negative number where there should have been a positive integer. We can specify additional symbols with the `na_values` argument:\n",
      "   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.read_csv(\"data/microbiome_missing.csv\", na_values=['?', -99999]).head(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These can be specified on a column-wise basis using an appropriate dict as the argument for `na_values`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several other data formats that can be imported into Python and converted into DataFrames, with the help of buitl-in or third-party libraries. These include Excel, JSON, XML, HDF5, relational and non-relational databases, and various web APIs. These are beyond the scope of this tutorial, but are covered in [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pandas Fundamentals"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section introduces the new user to the key functionality of Pandas that is required to use the software effectively.\n",
      "\n",
      "For some variety, we will leave our digestive tract bacteria behind and employ some baseball data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball = pd.read_csv(\"data/baseball.csv\", index_col='id')\n",
      "baseball.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that we specified the `id` column as the index, since it appears to be a unique identifier. We could try to create a unique index ourselves by combining `player` and `year`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "player_id = baseball.player + baseball.year.astype(str)\n",
      "baseball_newind = baseball.copy()\n",
      "baseball_newind.index = player_id\n",
      "baseball_newind.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.index.is_unique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, indices need not be unique. Our choice is not unique because some players change teams within years. The most important consequence of a non-unique index is that indexing by label will return multiple values for some labels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.ix['wickmbo012007']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will learn more about indexing below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Manipulating indices\n",
      "\n",
      "**Reindexing** allows users to manipulate the data labels in a DataFrame. It forces a DataFrame to conform to the new index, and optionally, fill in missing data if requested.\n",
      "\n",
      "A simple use of `reindex` is to alter the order of the rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.reindex(baseball.index[::-1]).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the `id` index is not sequential. Say we wanted to populate the table with every `id` value. We could specify and index that is a sequence from the first to the last `id` numbers in the database, and Pandas would fill in the missing data with `NaN` values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "id_range = range(baseball.index.values.min(), baseball.index.values.max())\n",
      "baseball.reindex(id_range).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Missing values can be filled as desired, either with selected values, or by rule:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.reindex(id_range, method='ffill', columns=['player','year']).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.reindex(id_range, fill_value='mr.nobody', columns=['player']).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keep in mind that `reindex` does not work if we pass a non-unique index series."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can remove rows or columns via the `drop` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.drop([89525, 89526])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.drop(['ibb','hbp'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Indexing and Selection\n",
      "\n",
      "Indexing works analogously to indexing in NumPy arrays, except we can use the labels in the `Index` object to extract values in addition to arrays of integers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sample Series object\n",
      "hits = baseball_newind.h\n",
      "hits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Numpy-style indexing\n",
      "hits[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Indexing by label\n",
      "hits[['womacto01CHN2006','schilcu01BOS2006']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also slice with data labels, since they have an intrinsic order within the Index:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hits['womacto01CHN2006':'gonzalu01ARI2006']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hits['womacto01CHN2006':'gonzalu01ARI2006'] = 5\n",
      "hits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In a `DataFrame` we can slice along either or both axes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind[['h','ab']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The indexing field `ix` allows us to select subsets of rows and columns in an intuitive way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.ix['gonzalu01ARI2006', ['h','X2b', 'X3b', 'hr']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.ix[['gonzalu01ARI2006','finlest01SFN2006'], 5:8]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.ix[:'myersmi01NYA2006', 'hr']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Operations\n",
      "\n",
      "`DataFrame` and `Series` objects allow for several operations to take place either on a single object, or between two or more objects.\n",
      "\n",
      "For example, we can perform arithmetic on the elements of two objects, such as combining baseball statistics across years:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hr2006 = baseball[baseball.year==2006].xs('hr', axis=1)\n",
      "hr2006.index = baseball.player[baseball.year==2006]\n",
      "\n",
      "hr2007 = baseball[baseball.year==2007].xs('hr', axis=1)\n",
      "hr2007.index = baseball.player[baseball.year==2007]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hr2006 = pd.Series(baseball.hr[baseball.year==2006].values, index=baseball.player[baseball.year==2006])\n",
      "hr2007 = pd.Series(baseball.hr[baseball.year==2007].values, index=baseball.player[baseball.year==2007])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hr_total = hr2006 + hr2007\n",
      "hr_total"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas' data alignment places `NaN` values for labels that do not overlap in the two Series. In fact, there are only 6 players that occur in both years."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hr_total[hr_total.notnull()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While we do want the operation to honor the data labels in this way, we probably do not want the missing values to be filled with `NaN`. We can use the `add` method to calculate player home run totals by using the `fill_value` argument to insert a zero for home runs where labels do not overlap:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hr2007.add(hr2006, fill_value=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Operations can also be **broadcast** between rows or columns.\n",
      "\n",
      "For example, if we subtract the maximum number of home runs hit from the `hr` column, we get how many fewer than the maximum were hit by each player:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.hr - baseball.hr.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, looking at things row-wise, we can see how a particular player compares with the rest of the group with respect to important statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.ix[89521][\"player\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = baseball[['h','X2b', 'X3b', 'hr']]\n",
      "diff = stats - stats.xs(89521)\n",
      "diff[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also apply functions to each column or row of a `DataFrame`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats.apply(np.median)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stat_range = lambda x: x.max() - x.min()\n",
      "stats.apply(stat_range)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets use apply to calculate a meaningful baseball statistics, slugging percentage:\n",
      "\n",
      "$$SLG = \\frac{1B + (2 \\times 2B) + (3 \\times 3B) + (4 \\times HR)}{AB}$$\n",
      "\n",
      "And just for fun, we will format the resulting estimate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slg = lambda x: (x['h']-x['X2b']-x['X3b']-x['hr'] + 2*x['X2b'] + 3*x['X3b'] + 4*x['hr'])/(x['ab']+1e-6)\n",
      "baseball.apply(slg, axis=1).apply(lambda x: '%.3f' % x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sorting and Ranking\n",
      "\n",
      "Pandas objects include methods for re-ordering data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.sort_index().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.sort_index(ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball_newind.sort_index(axis=1).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also use `order` to sort a `Series` by value, rather than by label."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.hr.order(ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a `DataFrame`, we can sort according to the values of one or more columns using the `by` argument of `sort_index`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball[['player','sb','cs']].sort_index(ascending=[False,True], by=['sb', 'cs']).head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Ranking** does not re-arrange data, but instead returns an index that ranks each value relative to others in the Series."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.hr.rank()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ties are assigned the mean value of the tied ranks, which may result in decimal values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series([100,100]).rank()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternatively, you can break ties via one of several methods, such as by the order in which they occur in the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.hr.rank(method='first')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calling the `DataFrame`'s `rank` method results in the ranks of all columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball.rank(ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseball[['r','h','hr']].rank(ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Missing data\n",
      "\n",
      "The occurence of missing data is so prevalent that it pays to use tools like Pandas, which seamlessly integrates missing data handling so that it can be dealt with easily, and in the manner required by the analysis at hand.\n",
      "\n",
      "Missing data are represented in `Series` and `DataFrame` objects by the `NaN` floating point value. However, `None` is also treated as missing, since it is commonly used as such in other contexts (*e.g.* NumPy)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foo = pd.Series([NaN, -3, None, 'foobar'])\n",
      "foo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foo.isnull()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Missing values may be dropped or indexed out:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2[bacteria2.notnull()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default, `dropna` drops entire rows in which one or more values are missing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be overridden by passing the `how='all'` argument, which only drops a row when every field is a missing value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.dropna(how='all')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be customized further by specifying how many values need to be present before a row is dropped via the `thresh` argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.ix[7, 'year'] = nan\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.dropna(thresh=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is typically used in time series applications, where there are repeated measurements that are incomplete for some subjects."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to drop missing values column-wise instead of row-wise, we use `axis=1`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.dropna(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rather than omitting missing data from an analysis, in some cases it may be suitable to fill the missing value in, either with a default value (such as zero) or a value that is either imputed or carried forward/backward from similar data points. We can do this programmatically in Pandas with the `fillna` argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.fillna({'year': 2013, 'treatment':2})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that `fillna` by default returns a new object with the desired filling behavior, rather than changing the `Series` or  `DataFrame` in place (**in general, we like to do this, by the way!**)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can alter values in-place using `inplace=True`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = data.year.fillna(2013, inplace=True)\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Missing values can also be interpolated, using any one of a variety of methods:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2.fillna(method='bfill')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bacteria2.fillna(bacteria2.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Merging and joining DataFrame objects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section, we will manipulate data collected from ocean-going vessels on the eastern seaboard. Vessel operations are monitored using the Automatic Identification System (AIS), a safety at sea navigation technology which vessels are required to maintain and that uses transponders to transmit very high frequency (VHF) radio signals containing static information including ship name, call sign, and country of origin, as well as dynamic information unique to a particular voyage such as vessel location, heading, and speed. \n",
      "\n",
      "The International Maritime Organization\u2019s (IMO) International Convention for the Safety of Life at Sea requires functioning AIS capabilities on all vessels 300 gross tons or greater and the US Coast Guard requires AIS on nearly all vessels sailing in U.S. waters. The Coast Guard has established a national network of AIS receivers that provides coverage of nearly all U.S. waters. AIS signals are transmitted several times each minute and the network is capable of handling thousands of reports per minute and updates as often as every two seconds. Therefore, a typical voyage in our study might include the transmission of hundreds or thousands of AIS encoded signals. This provides a rich source of spatial data that includes both spatial and temporal information.\n",
      "\n",
      "For our purposes, we will use summarized data that describes the transit of a given vessel through a particular administrative area. The data includes the start and end time of the transit segment, as well as information about the speed of the vessel, how far it travelled, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments = pd.read_csv(\"data/AIS/transit_segments.csv\")\n",
      "segments.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the behavior of each vessel, we may want a little more information regarding the vessels themselves. In the `data/AIS` folder there is a second table that contains information about each of the ships that traveled the segments in the `segments` table."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vessels = pd.read_csv(\"data/AIS/vessel_information.csv\", index_col='mmsi')\n",
      "vessels.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vessels.type.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The challenge, however, is that several ships have travelled multiple segments, so there is not a one-to-one relationship between the rows of the two tables. The table of vessel information has a *one-to-many* relationship with the segments.\n",
      "\n",
      "In Pandas, we can combine tables according to the value of one or more *keys* that are used to identify rows, much like an index. Using a trivial example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1 = pd.DataFrame(dict(id=range(4), age=np.random.randint(18, 31, size=4)))\n",
      "df2 = pd.DataFrame(dict(id=range(3)+range(3), score=np.random.random(size=6)))\n",
      "\n",
      "df1, df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.merge(df1, df2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that without any information about which column to use as a key, Pandas did the right thing and used the `id` column in both tables. Unless specified otherwise, `merge` will used any common column names as keys for merging the tables. \n",
      "\n",
      "Notice also that `id=3` from `df1` was omitted from the merged table. This is because, by default, `merge` performs an **inner join** on the tables, meaning that the merged table represents an intersection of the two tables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.merge(df1, df2, how='outer')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The **outer join** above yields the union of the two tables, so all rows are represented, with missing values inserted as appropriate. One can also perform **right** and **left** joins to include all rows of the right or left table (*i.e.* first or second argument to `merge`), but not necessarily the other.\n",
      "\n",
      "Looking at the two datasets that we wish to merge:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments.head(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vessels.head(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we see that there is a `mmsi` value (a vessel identifier) in each table, but it is used as an index for the `vessels` table. In this case, we have to specify to join on the index for this table, and on the `mmsi` column for the other."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments_merged = pd.merge(vessels, segments, left_index=True, right_on='mmsi')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments_merged.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, the default inner join is suitable; we are not interested in observations from either table that do not have corresponding entries in the other. \n",
      "\n",
      "Notice that `mmsi` field that was an index on the `vessels` table is no longer an index on the merged table.\n",
      "\n",
      "Here, we used the `merge` function to perform the merge; we could also have used the `merge` method for either of the tables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vessels.merge(segments, left_index=True, right_on='mmsi').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Occasionally, there will be fields with the same in both tables that we do not wish to use to join the tables; they may contain different information, despite having the same name. In this case, Pandas will by default append suffixes `_x` and `_y` to the columns to uniquely identify them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments['type'] = 'foo'\n",
      "pd.merge(vessels, segments, left_index=True, right_on='mmsi').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This behavior can be overridden by specifying a `suffixes` argument, containing a list of the suffixes to be used for the columns of the left and right columns, respectively."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Concatenation\n",
      "\n",
      "A common data manipulation is appending rows or columns to a dataset that already conform to the dimensions of the exsiting rows or colums, respectively. In NumPy, this is done either with `concatenate` or the convenience functions `c_` and `r_`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.concatenate([np.random.random(5), np.random.random(5)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.r_[np.random.random(5), np.random.random(5)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.c_[np.random.random(5), np.random.random(5)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This operation is also called *binding* or *stacking*.\n",
      "\n",
      "With Pandas' indexed data structures, there are additional considerations as the overlap in index values between two data structures affects how they are concatenate.\n",
      "\n",
      "Lets import two microbiome datasets, each consisting of counts of microorganiams from a particular patient. We will use the first column of each dataset as the index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1 = pd.read_excel('data/microbiome/MID1.xls', 'Sheet 1', index_col=0, header=None)\n",
      "mb2 = pd.read_excel('data/microbiome/MID2.xls', 'Sheet 1', index_col=0, header=None)\n",
      "mb1.shape, mb2.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's give the index and columns meaningful labels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.columns = mb2.columns = ['Count']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.index.name = mb2.index.name = 'Taxon'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The index of these data is the unique biological classification of each organism, beginning with *domain*, *phylum*, *class*, and for some organisms, going all the way down to the genus level.\n",
      "\n",
      "![classification](http://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Biological_classification_L_Pengo_vflip.svg/150px-Biological_classification_L_Pengo_vflip.svg.png)\n",
      "<div align=\"right\">*(Source: Wikipedia)*</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.index[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.index.is_unique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we concatenate along `axis=0` (the default), we will obtain another data frame with the the rows concatenated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat([mb1, mb2], axis=0).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, the index is no longer unique, due to overlap between the two DataFrames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat([mb1, mb2], axis=0).index.is_unique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Concatenating along `axis=1` will concatenate column-wise, but respecting the indices of the two DataFrames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat([mb1, mb2], axis=1).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat([mb1, mb2], axis=1).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat([mb1, mb2], axis=1).values[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we are only interested in taxa that are included in both DataFrames, we can specify a `join=inner` argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat([mb1, mb2], axis=1, join='inner').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wanted to use the second table to fill values absent from the first table, we could use `combine_first`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb1.combine_first(mb2).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternatively, you can pass keys to the concatenation by supplying the DataFrames (or Series) as a dict."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.concat(dict(patient1=mb1, patient2=mb2), axis=1).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want `concat` to work like `numpy.concatanate`, you may provide the `ignore_index=True` argument."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reshaping DataFrame objects\n",
      "\n",
      "In the context of a single DataFrame, we are often interested in re-arranging the layout of our data. \n",
      "\n",
      "This dataset in from Table 6.9 of [Statistical Methods for the Analysis of Repeated Measurements](http://www.amazon.com/Statistical-Methods-Analysis-Repeated-Measurements/dp/0387953701) by Charles S. Davis, pp. 161-163 (Springer, 2002). These data are from a multicenter, randomized controlled trial of botulinum toxin type B (BotB) in patients with cervical dystonia from nine U.S. sites.\n",
      "\n",
      "* Randomized to placebo (N=36), 5000 units of BotB (N=36), 10,000 units of BotB (N=37)\n",
      "* Response variable: total score on Toronto Western Spasmodic Torticollis Rating Scale (TWSTRS), measuring severity, pain, and disability of cervical dystonia (high scores mean more impairment)\n",
      "* TWSTRS measured at baseline (week 0) and weeks 2, 4, 8, 12, 16 after treatment began"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia = pd.read_csv(\"data/cdystonia.csv\", index_col=None)\n",
      "cdystonia.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This dataset includes repeated measurements of the same individuals (longitudinal data). Its possible to present such information in (at least) two ways: showing each repeated measurement in their own row, or in multiple columns representing mutliple measurements.\n",
      "\n",
      "The `stack` method rotates the data frame so that columns are represented in rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stacked = cdystonia.stack()\n",
      "stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To complement this, `unstack` pivots from rows back to columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stacked.unstack().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this dataset, it makes sense to create a hierarchical index based on the patient and observation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia2 = cdystonia.set_index(['patient','obs'])\n",
      "cdystonia2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia2.index.is_unique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to transform this data so that repeated measurements are in columns, we can `unstack` the `twstrs` measurements according to `obs`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twstrs_wide = cdystonia2['twstrs'].unstack('obs')\n",
      "twstrs_wide.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_long = cdystonia[['patient','site','id','treat','age','sex']].drop_duplicates().merge(\n",
      "                    twstrs_wide, right_index=True, left_on='patient', how='inner').head()\n",
      "cdystonia_long"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A slightly cleaner way of doing this is to set the patient-level information as an index before unstacking:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia.set_index(['patient','site','id','treat','age','sex','week'])['twstrs'].unstack('week').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To convert our \"wide\" format back to long, we can use the `melt` function, appropriately parameterized:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.melt(cdystonia_long, id_vars=['patient','site','id','treat','age','sex'], \n",
      "        var_name='obs', value_name='twsters').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This illustrates the two formats for longitudinal data: **long** and **wide** formats. Its typically better to store data in long format because additional data can be included as additional rows in the database, while wide format requires that the entire database schema be altered by adding columns to every row as data are collected.\n",
      "\n",
      "The preferable format for analysis depends entirely on what is planned for the data, so it is imporant to be able to move easily between them."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data transformation\n",
      "\n",
      "There are a slew of additional operations for DataFrames that we would collectively refer to as \"transformations\" that include tasks such as removing duplicate values, replacing values, and grouping values.\n",
      "\n",
      "### Dealing with duplicates\n",
      "\n",
      "We can easily identify and remove duplicate values from `DataFrame` objects. For example, say we want to removed ships from our `vessels` dataset that have the same name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vessels.duplicated(cols='names')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vessels.drop_duplicates(['names'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Value replacement\n",
      "\n",
      "Frequently, we get data columns that are encoded as strings that we wish to represent numerically for the purposes of including it in a quantitative analysis. For example, consider the treatment variable in the cervical dystonia dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia.treat.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A logical way to specify these numerically is to change them to integer values, perhaps using \"Placebo\" as a baseline value. If we create a dict with the original values as keys and the replacements as values, we can pass it to the `map` method to implement the changes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treatment_map = {'Placebo': 0, '5000U': 1, '10000U': 2}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia['treatment'] = cdystonia.treat.map(treatment_map)\n",
      "cdystonia.treatment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternately, if we simply want to replace particular values in a `Series` or `DataFrame`, we can use the `replace` method. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia2.treat.replace({'Placebo': 0, '5000U': 1, '10000U': 2})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data aggregation and GroupBy operations\n",
      "\n",
      "One of the most powerful features of Pandas is its **GroupBy** functionality. On occasion we may want to perform operations on *groups* of observations within a dataset. For exmaple:\n",
      "\n",
      "* **aggregation**, such as computing the sum of mean of each group, which involves applying a function to each group and returning the aggregated results\n",
      "* **slicing** the DataFrame into groups and then doing something with the resulting slices (*e.g.* plotting)\n",
      "* group-wise **transformation**, such as standardization/normalization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_grouped = cdystonia.groupby(cdystonia.patient)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This *grouped* dataset is hard to visualize\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_grouped"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, the grouping is only an intermediate step; for example, we may want to **iterate** over each of the patient groups:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for patient, group in cdystonia_grouped:\n",
      "    print patient\n",
      "    print group\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A common data analysis procedure is the **split-apply-combine** operation, which groups subsets of data together, applies a function to each of the groups, then recombines them into a new data table.\n",
      "\n",
      "For example, we may want to aggregate our data with with some function.\n",
      "\n",
      "![split-apply-combine](http://f.cl.ly/items/0s0Z252j0X0c3k3P1M47/Screen%20Shot%202013-06-02%20at%203.04.04%20PM.png)\n",
      "\n",
      "<div align=\"right\">*(Source: \"Python for Data Analysis\", p.251)*</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can aggregate in Pandas using the `aggregate` (or `agg`, for short) method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_grouped.agg(np.mean).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the `treat` and `sex` variables are not included in the aggregation. Since it does not make sense to aggregate non-string variables, these columns are simply ignored by the method.\n",
      "\n",
      "Some aggregation functions are so common that Pandas has a convenience method for them, such as `mean`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_grouped.mean().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `add_prefix` and `add_suffix` methods can be used to give the columns of the resulting table labels that reflect the transformation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_grouped.mean().add_suffix('_mean').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The median of the `twstrs` variable\n",
      "cdystonia_grouped['twstrs'].quantile(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wish, we can easily aggregate according to multiple keys:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia.groupby(['week','site']).mean().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternately, we can **transform** the data, using a function of our choice with the `transform` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalize = lambda x: (x - x.mean())/x.std()\n",
      "\n",
      "cdystonia_grouped.transform(normalize).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is easy to do column selection within `groupby` operations, if we are only interested split-apply-combine operations on a subset of columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdystonia_grouped['twstrs'].mean().head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you simply want to divide your DataFrame into chunks for later use, its easy to convert them into a dict so that they can be easily indexed out as needed:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunks = dict(list(cdystonia_grouped))\n",
      "chunks[4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default, `groupby` groups by row, but we can specify the `axis` argument to change this. For example, we can group our columns by type this way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict(list(cdystonia.groupby(cdystonia.dtypes, axis=1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply\n",
      "\n",
      "We can generalize the split-apply-combine methodology by using `apply` function. This allows us to invoke any function we wish on a grouped dataset and recombine them into a DataFrame.\n",
      "\n",
      "The function below takes a DataFrame and a column name, sorts by the column, and takes the `n` largest values of that column. We can use this with `apply` to return the largest values from every group in a DataFrame in a single call. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def top(df, column, n=5):\n",
      "    return df.sort_index(by=column, ascending=False)[:n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see this in action, consider the vessel transit segments dataset (which we merged with the vessel information to yield `segments_merged`). Say we wanted to return the 3 longest segments travelled by each ship:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top3segments = segments_merged.groupby('mmsi').apply(top, column='seg_length', n=3)[['names', 'seg_length']]\n",
      "top3segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that additional arguments for the applied function can be passed via `apply` after the function name. It assumes that the DataFrame is the first argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top3segments.head(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}